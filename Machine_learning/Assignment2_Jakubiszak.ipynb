{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1738aa6d",
      "metadata": {
        "id": "1738aa6d"
      },
      "source": [
        "### Assignment 2 - Machine Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a21d1144",
      "metadata": {
        "id": "a21d1144"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd56580",
      "metadata": {
        "id": "ebd56580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "8b2c1d52-e304-4db4-b448-56d7216a0e93"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'mnist_loader.py' was not found in history, as a file, url, nor in the user namespace.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mfind_user_code\u001b[0;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[1;32m   3877\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m                                              \u001b[0;31m# User namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3878\u001b[0;31m             \u001b[0mcodeobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3879\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mnist_loader' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-464895301b07>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mnist_loader.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \"\"\"\n\u001b[1;32m      3\u001b[0m \u001b[0mmnist_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMNIST\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mFor\u001b[0m \u001b[0mdetails\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-39>\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, arg_s)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/code.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0msearch_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'n'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_user_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_ns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m's'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mfind_user_code\u001b[0;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[1;32m   3878\u001b[0m             \u001b[0mcodeobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3879\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3880\u001b[0;31m             raise ValueError((\"'%s' was not found in history, as a file, url, \"\n\u001b[0m\u001b[1;32m   3881\u001b[0m                                 \"nor in the user namespace.\") % target)\n\u001b[1;32m   3882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'mnist_loader.py' was not found in history, as a file, url, nor in the user namespace."
          ]
        }
      ],
      "source": [
        "%load mnist_loader.py\n",
        "\"\"\"\n",
        "mnist_loader\n",
        "~~~~~~~~~~~~\n",
        "A library to load the MNIST image data.  For details of the data\n",
        "structures that are returned, see the doc strings for ``load_data``\n",
        "and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the\n",
        "function usually called by our neural network code.\n",
        "\"\"\"\n",
        "\n",
        "#### Libraries\n",
        "# Standard library\n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "# Third-party libraries\n",
        "import numpy as np\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Return the MNIST data as a tuple containing the training data,\n",
        "    the validation data, and the test data.\n",
        "    The ``training_data`` is returned as a tuple with two entries.\n",
        "    The first entry contains the actual training images.  This is a\n",
        "    numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n",
        "    numpy ndarray with 784 values, representing the 28 * 28 = 784\n",
        "    pixels in a single MNIST image.\n",
        "    The second entry in the ``training_data`` tuple is a numpy ndarray\n",
        "    containing 50,000 entries.  Those entries are just the digit\n",
        "    values (0...9) for the corresponding images contained in the first\n",
        "    entry of the tuple.\n",
        "    The ``validation_data`` and ``test_data`` are similar, except\n",
        "    each contains only 10,000 images.\n",
        "    This is a nice data format, but for use in neural networks it's\n",
        "    helpful to modify the format of the ``training_data`` a little.\n",
        "    That's done in the wrapper function ``load_data_wrapper()``, see\n",
        "    below.\n",
        "    \"\"\"\n",
        "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
        "    training_data, validation_data, test_data = pickle.load(f, encoding=\"latin1\")\n",
        "    f.close()\n",
        "    return (training_data, validation_data, test_data)\n",
        "\n",
        "def load_data_wrapper():\n",
        "    \"\"\"Return a tuple containing ``(training_data, validation_data,\n",
        "    test_data)``. Based on ``load_data``, but the format is more\n",
        "    convenient for use in our implementation of neural networks.\n",
        "    In particular, ``training_data`` is a list containing 50,000\n",
        "    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray\n",
        "    containing the input image.  ``y`` is a 10-dimensional\n",
        "    numpy.ndarray representing the unit vector corresponding to the\n",
        "    correct digit for ``x``.\n",
        "    ``validation_data`` and ``test_data`` are lists containing 10,000\n",
        "    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional\n",
        "    numpy.ndarry containing the input image, and ``y`` is the\n",
        "    corresponding classification, i.e., the digit values (integers)\n",
        "    corresponding to ``x``.\n",
        "    Obviously, this means we're using slightly different formats for\n",
        "    the training data and the validation / test data.  These formats\n",
        "    turn out to be the most convenient for use in our neural network\n",
        "    code.\"\"\"\n",
        "    tr_d, va_d, te_d = load_data()\n",
        "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
        "    training_results = [vectorized_result(y) for y in tr_d[1]]\n",
        "    #print(training_results[0])\n",
        "    training_data = zip(training_inputs, training_results)\n",
        "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
        "    validation_data = zip(validation_inputs, va_d[1])\n",
        "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
        "    test_data = zip(test_inputs, te_d[1])\n",
        "    return (training_data, validation_data, test_data)\n",
        "\n",
        "def vectorized_result(j):\n",
        "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
        "    position and zeroes elsewhere.  This is used to convert a digit\n",
        "    (0...9) into a corresponding desired output from the neural\n",
        "    network.\"\"\"\n",
        "    e = np.zeros((10, 1))\n",
        "    e[j] = 1.0\n",
        "    return e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d544502",
      "metadata": {
        "id": "3d544502"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd87484",
      "metadata": {
        "id": "8dd87484"
      },
      "outputs": [],
      "source": [
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, num_neurons=16, num_layers=2, input_size=784, output_size=10):\n",
        "        '''Initialize the NeuralNetwork with specified parameters.'''\n",
        "        self.weights = []\n",
        "        denominator = np.sqrt(input_size * output_size)\n",
        "\n",
        "        # Initialize the first layer\n",
        "        first_layer_shape = (num_neurons, input_size + 1)\n",
        "        self.weights.append(np.random.normal(0, 1/denominator, first_layer_shape))\n",
        "\n",
        "        # Initialize intermediate layers (if any)\n",
        "        for _ in range(num_layers - 2):\n",
        "            intermediate_layer_shape = (num_neurons, num_neurons + 1)\n",
        "            self.weights.append(np.random.normal(0, 1/denominator, intermediate_layer_shape))\n",
        "\n",
        "        # Initialize the last layer\n",
        "        last_layer_shape = (output_size, num_neurons + 1)\n",
        "        self.weights.append(np.random.normal(0, 1/denominator, last_layer_shape))\n",
        "\n",
        "    def match(self, pixels):\n",
        "        '''Returns predicted number for the given input pixels.'''\n",
        "\n",
        "        # Initialize input vector with bias term\n",
        "        input_vector = np.vstack(([1], pixels))\n",
        "\n",
        "        # Forward Pass Through Layers\n",
        "        activation_vectors = [self.forward_pass(input_vector)]\n",
        "\n",
        "        # Return the predicted number based on the output layer\n",
        "        return np.argmax(activation_vectors[-1])\n",
        "\n",
        "    def forward_pass(self, input_vector):\n",
        "        '''Performs a forward pass through the neural network.'''\n",
        "\n",
        "        # Initialize the activation vector\n",
        "        activation_vector = sigmoid(self.weights[0].dot(input_vector))\n",
        "\n",
        "        # Iterative Forward Pass Through Layers\n",
        "        for weight_matrix in self.weights[1:]:\n",
        "            input_vector = np.vstack(([1], activation_vector))\n",
        "            net_input = weight_matrix.dot(input_vector)\n",
        "            activation_vector = sigmoid(net_input)\n",
        "\n",
        "        return activation_vector\n",
        "\n",
        "    def fit(self, pixels): #any version\n",
        "        '''Function that returns predicted vector for input vector of pixes.\n",
        "        '''\n",
        "        rozmiar = len(self.weights)\n",
        "\n",
        "        # Fast forward\n",
        "        Xs = [np.vstack(([1], pixels))]\n",
        "        As = [sigmoid(self.weights[0].dot(Xs[0]))]\n",
        "\n",
        "        for step in range(1, rozmiar):\n",
        "            Xs.append(np.vstack(([1], As[-1])))\n",
        "            net = self.weights[step].dot(Xs[step])\n",
        "            As.append(sigmoid(net))\n",
        "\n",
        "        return As[-1]\n",
        "\n",
        "    def calculate_accuracy(self, input_list, target_list):\n",
        "        '''Calculates the accuracy of predicted numbers compared to the target vectors for a set of inputs.'''\n",
        "\n",
        "\n",
        "        correct_predictions = sum(self.match(input_data) == np.argmax(target_data) for input_data, target_data in zip(input_list, target_list))\n",
        "        total_inputs = len(input_list)\n",
        "\n",
        "        accuracy = correct_predictions / total_inputs\n",
        "        return accuracy\n",
        "\n",
        "    def test_predictions(self, input_list, target_list):\n",
        "        '''Evaluates the correctness of predicted values compared to the target values for a set of inputs.'''\n",
        "\n",
        "        correct_predictions = sum(self.match(input_data) == target_data for input_data, target_data in zip(input_list, target_list))\n",
        "        total_inputs = len(input_list)\n",
        "        return correct_predictions / total_inputs\n",
        "\n",
        "\n",
        "    def train_epochs(self, input_data, target_data, learning_rate=0.1, num_epochs=100):\n",
        "        '''Trains the neural network using online learning for a specified number of epochs.'''\n",
        "        num_examples = np.shape(input_data)[0]\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Shuffle the data for each epoch\n",
        "            shuffled_data = list(zip(input_data, target_data))\n",
        "            random.shuffle(shuffled_data)\n",
        "            input_data, target_data = zip(*shuffled_data)\n",
        "\n",
        "            for example in range(num_examples):\n",
        "                input_vector = input_data[example]\n",
        "                target_vector = target_data[example]\n",
        "\n",
        "                # Forward pass\n",
        "                input_layer = np.vstack(([1], input_vector))\n",
        "                net_hidden = self.weights[0].dot(input_layer)\n",
        "                activation_hidden = sigmoid(net_hidden)\n",
        "                input_with_bias = np.vstack(([1], activation_hidden))\n",
        "                net_output = self.weights[1].dot(input_with_bias)\n",
        "                activation_output = sigmoid(net_output)\n",
        "\n",
        "                # Backpropagation\n",
        "                output_error = activation_output - target_vector\n",
        "                delta_output = output_error * activation_output * (1 - activation_output)\n",
        "                grad_output_weights = delta_output.dot(input_with_bias.T)\n",
        "\n",
        "                delta_hidden = (self.weights[1].T).dot(delta_output)[1:] * activation_hidden * (1 - activation_hidden)\n",
        "                grad_hidden_weights = delta_hidden.dot(input_layer.T)\n",
        "\n",
        "                # Update weights\n",
        "                self.weights[0] -= learning_rate * grad_hidden_weights\n",
        "                self.weights[1] -= learning_rate * grad_output_weights\n",
        "\n",
        "            print('Epoch', epoch + 1)\n",
        "\n",
        "\n",
        "    def train_batch(self, input_data, target_data, learning_rate=0.1, num_epochs=10, batch_size=1):\n",
        "        '''Updates weights using batch learning for 2 layers.'''\n",
        "        num_examples = np.shape(input_data)[0]\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Shuffle the data for each epoch\n",
        "            shuffled_data = list(zip(input_data, target_data))\n",
        "            random.shuffle(shuffled_data)\n",
        "            input_data, target_data = zip(*shuffled_data)\n",
        "\n",
        "            # Calculate the number of batches\n",
        "            num_batches = int(num_examples / batch_size)\n",
        "            print('Epoch', epoch + 1)\n",
        "\n",
        "            for batch_idx in range(num_batches):\n",
        "                W1_gradients = []\n",
        "                W2_gradients = []\n",
        "                current_input = input_data[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
        "                current_target = target_data[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
        "\n",
        "                for example_idx in range(batch_size):\n",
        "                    input_vector = current_input[example_idx]\n",
        "                    target_vector = current_target[example_idx]\n",
        "\n",
        "                    # Forward pass\n",
        "                    input_with_bias = np.vstack(([1], input_vector))\n",
        "                    net_hidden = self.weights[0].dot(input_with_bias)\n",
        "                    activation_hidden = sigmoid(net_hidden)\n",
        "                    input_output_with_bias = np.vstack(([1], activation_hidden))\n",
        "                    net_output = self.weights[1].dot(input_output_with_bias)\n",
        "                    activation_output = sigmoid(net_output)\n",
        "\n",
        "                    # Backpropagation\n",
        "                    output_error = activation_output - target_vector\n",
        "                    delta_output = output_error * activation_output * (1 - activation_output)\n",
        "                    W2_gradients.append(delta_output.dot(input_output_with_bias.T))\n",
        "\n",
        "                    delta_hidden = (self.weights[1].T).dot(delta_output)[1:] * activation_hidden * (1 - activation_hidden)\n",
        "                    W1_gradients.append(delta_hidden.dot(input_with_bias.T))\n",
        "\n",
        "                # Update weights\n",
        "                self.weights[0] -= learning_rate * sum(W1_gradients) / batch_size\n",
        "                self.weights[1] -= learning_rate * sum(W2_gradients) / batch_size\n",
        "\n",
        "    def online_multi_layer(self, input_list, result_list, c=0.1, n=100):\n",
        "        '''Online learning for case with any number of layers.'''\n",
        "        training_size = np.shape(input_list)[0]\n",
        "\n",
        "        for epoch in range(n):\n",
        "            print('Epoch', epoch + 1)\n",
        "            shuffled_data = list(zip(input_list, result_list))\n",
        "            random.shuffle(shuffled_data)\n",
        "            input_list, result_list = zip(*shuffled_data)\n",
        "\n",
        "            for item in range(training_size):\n",
        "                input = input_list[item]\n",
        "                output = result_list[item]\n",
        "                num_layers = len(self.weights)\n",
        "\n",
        "                # Forward pass\n",
        "                inputs = [np.vstack(([1], input))]\n",
        "                activations = [sigmoid(self.weights[0].dot(inputs[0]))]\n",
        "\n",
        "                for step in range(1, num_layers):\n",
        "                    inputs.append(np.vstack(([1], activations[-1])))\n",
        "                    net = self.weights[step].dot(inputs[step])\n",
        "                    activations.append(sigmoid(net))\n",
        "\n",
        "                # Backpropagation\n",
        "                loss = activations[-1] - output\n",
        "                delta_output = loss * activations[-1] * (1 - activations[-1])\n",
        "                weight_gradients = [delta_output.dot(inputs[-2].T)]\n",
        "\n",
        "                for step in range(num_layers - 2, -1, -1):\n",
        "                    dLa1 = (self.weights[step + 1].T).dot(delta_output)[1:]\n",
        "                    delta_hidden = dLa1 * activations[step] * (1 - activations[step])\n",
        "                    delta_output = delta_hidden  # Update delta_output for the next layer\n",
        "                    weight_gradients.append(delta_hidden.dot(inputs[step].T))\n",
        "\n",
        "                # Update weights\n",
        "                for i in range(num_layers):\n",
        "                    self.weights[i] -= c * weight_gradients[-i - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a4a00c",
      "metadata": {
        "id": "14a4a00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "6f49c5d5-df30-400e-9407-55298af06cd9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'mnist.pkl.gz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-845981edbf06>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Upload our data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtr_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_d\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mload_data_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b34e75cb5780>\u001b[0m in \u001b[0;36mload_data_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mconvenient\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mour\u001b[0m \u001b[0mneural\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     code.\"\"\"\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mtr_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mtraining_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mtraining_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvectorized_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b34e75cb5780>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mbelow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \"\"\"\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist.pkl.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist.pkl.gz'"
          ]
        }
      ],
      "source": [
        "# Upload our data\n",
        "tr_d, va_d, te_d  = load_data_wrapper()\n",
        "input_list, result_list = zip(*list(tr_d))\n",
        "input_test, result_test = zip(*list(te_d))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b2d5151",
      "metadata": {
        "id": "5b2d5151"
      },
      "outputs": [],
      "source": [
        "# Create our network\n",
        "network1 = NeuralNetwork(16, 2, 784, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0bc1363",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0bc1363",
        "outputId": "09a96fc3-7bb6-43ac-b0a1-78e624fd3bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Train data accuracy 0.9647\n",
            "Test data accuracy 0.9442\n"
          ]
        }
      ],
      "source": [
        "#online 2 layer\n",
        "epochs = 10\n",
        "\n",
        "network1.train_epochs(input_list, result_list, 0.1, epochs)\n",
        "\n",
        "print('Train data accuracy', network1.calculate_accuracy(input_list, result_list))\n",
        "\n",
        "print('Test data accuracy', network1.test_predictions(input_test, result_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6c9c33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a6c9c33",
        "outputId": "d99011a2-0ed7-43f4-c3ce-c11ab801f061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Train data accuracy 0.9285\n",
            "Test data accuracy 0.9298\n"
          ]
        }
      ],
      "source": [
        "#batch 2 layer\n",
        "network2 = NeuralNetwork(16, 2, 784, 10)\n",
        "\n",
        "network2.train_batch(input_list, result_list, 0.1, epochs, 10)\n",
        "\n",
        "\n",
        "print('Train data accuracy', network2.calculate_accuracy(input_list, result_list))\n",
        "\n",
        "print('Test data accuracy', network2.test_predictions(input_test, result_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d805e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "f2d805e9",
        "outputId": "9c87b5a7-fc26-4ec4-e632-69fcd7dee8ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'input_list' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f5cb42f33be2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#online more layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnetwork_3layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnetwork_3layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monline_multi_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train data accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_3layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_list' is not defined"
          ]
        }
      ],
      "source": [
        "#online more layers\n",
        "network_3layers = NeuralNetwork(16,3,784,10)\n",
        "network_3layers.online_multi_layer(input_list, result_list, 0.1, 10)\n",
        "\n",
        "print('Train data accuracy', network_3layers.calculate_accuracy(input_list, result_list))\n",
        "\n",
        "print('Test data accuracy', network_3layers.test_predictions(input_test, result_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N1jaO98afMp9"
      },
      "id": "N1jaO98afMp9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}